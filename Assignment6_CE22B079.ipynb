{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb2dd33",
   "metadata": {},
   "source": [
    "# DA5401 Assignment 6 \n",
    "## CE22B079, Sasanka Marthand N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f547569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasank/DA5401/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93807aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied to: /home/sasank/DA5401/assignment-6-sasank2004/data\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"uciml/default-of-credit-card-clients-dataset\")\n",
    "dest = \"./data\"\n",
    "shutil.copytree(path, dest, dirs_exist_ok=True)\n",
    "print(\"Files copied to:\", os.path.abspath(dest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ab672",
   "metadata": {},
   "source": [
    "## Part A: Data Preprocessing and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9efd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 25)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LIMIT_BAL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SEX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EDUCATION",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MARRIAGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PAY_6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BILL_AMT1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BILL_AMT2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BILL_AMT3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BILL_AMT4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BILL_AMT5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BILL_AMT6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PAY_AMT6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "default.payment.next.month",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "79ba520e-7aa8-4e0c-94bc-e9f4f2f86acf",
       "rows": [
        [
         "0",
         "1",
         "20000.0",
         "2",
         "2",
         "1",
         "24",
         "2",
         "2",
         "-1",
         "-1",
         "-2",
         "-2",
         "3913.0",
         "3102.0",
         "689.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "689.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1"
        ],
        [
         "1",
         "2",
         "120000.0",
         "2",
         "2",
         "2",
         "26",
         "-1",
         "2",
         "0",
         "0",
         "0",
         "2",
         "2682.0",
         "1725.0",
         "2682.0",
         "3272.0",
         "3455.0",
         "3261.0",
         "0.0",
         "1000.0",
         "1000.0",
         "1000.0",
         "0.0",
         "2000.0",
         "1"
        ],
        [
         "2",
         "3",
         "90000.0",
         "2",
         "2",
         "2",
         "34",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "29239.0",
         "14027.0",
         "13559.0",
         "14331.0",
         "14948.0",
         "15549.0",
         "1518.0",
         "1500.0",
         "1000.0",
         "1000.0",
         "1000.0",
         "5000.0",
         "0"
        ],
        [
         "3",
         "4",
         "50000.0",
         "2",
         "2",
         "1",
         "37",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "46990.0",
         "48233.0",
         "49291.0",
         "28314.0",
         "28959.0",
         "29547.0",
         "2000.0",
         "2019.0",
         "1200.0",
         "1100.0",
         "1069.0",
         "1000.0",
         "0"
        ],
        [
         "4",
         "5",
         "50000.0",
         "1",
         "2",
         "1",
         "57",
         "-1",
         "0",
         "-1",
         "0",
         "0",
         "0",
         "8617.0",
         "5670.0",
         "35835.0",
         "20940.0",
         "19146.0",
         "19131.0",
         "2000.0",
         "36681.0",
         "10000.0",
         "9000.0",
         "689.0",
         "679.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dest+'/UCI_Credit_Card.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad46cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE          0\n",
      "BILL_AMT1    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['AGE', 'BILL_AMT1']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e68b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df created\n",
      "MAR introduced in 'AGE': 1500 NaNs added.\n",
      "MAR introduced in 'BILL_AMT1': 1500 NaNs added.\n",
      "MAR introduced in 'LIMIT_BAL': 1500 NaNs added.\n",
      "\n",
      "Final NaN counts in selected columns:\n",
      "AGE          1500\n",
      "BILL_AMT1    1500\n",
      "LIMIT_BAL    1500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_MAR = df.copy()\n",
    "    print(\"New df created\")\n",
    "except FileNotFoundError:\n",
    "    print(\"df Error\")\n",
    "\n",
    "df_MAR = df_MAR.reset_index(drop=True)\n",
    "\n",
    "def introduce_mar(dataframe, target_col, predictor_condition, mar_pct=0.05):\n",
    "    \n",
    "    num_to_miss = int(len(dataframe) * mar_pct)\n",
    "    weights = np.where(predictor_condition, 3, 1)  # 3x bias\n",
    "    probabilities = weights / np.sum(weights)\n",
    "\n",
    "    missing_indices = np.random.choice(\n",
    "        dataframe.index,\n",
    "        size=num_to_miss,\n",
    "        replace=False,\n",
    "        p=probabilities\n",
    "    )\n",
    "    dataframe.loc[missing_indices, target_col] = np.nan\n",
    "    print(f\"MAR introduced in '{target_col}': {len(missing_indices)} NaNs added.\")\n",
    "\n",
    "\n",
    "MAR_PERCENTAGE = 0.05  # 5%\n",
    "\n",
    "age_predictor = df_MAR['EDUCATION'].isin([1, 2])\n",
    "introduce_mar(df_MAR, 'AGE', age_predictor, MAR_PERCENTAGE)\n",
    "\n",
    "bill_predictor = df_MAR['PAY_0'].isin([3, 4, 5, 6])\n",
    "introduce_mar(df_MAR, 'BILL_AMT1', bill_predictor, MAR_PERCENTAGE)\n",
    "\n",
    "limit_predictor = (df_MAR['MARRIAGE'] == 1)\n",
    "introduce_mar(df_MAR, 'LIMIT_BAL', limit_predictor, MAR_PERCENTAGE)\n",
    "\n",
    "missing_cols = ['AGE', 'BILL_AMT1', 'LIMIT_BAL']\n",
    "print(\"\\nFinal NaN counts in selected columns:\")\n",
    "print(df_MAR[missing_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101f211",
   "metadata": {},
   "source": [
    "### Missing at Random (MAR)\n",
    "\n",
    "We created missing values in a way that depends on other known factors : for example, AGE values are more likely to be missing for people with higher education, or BILL_AMT1 is more likely missing when payment delays are severe. This means the missingness is related to observed variables, not random or dependent on the missing value itself making it Missing At Random (MAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fd2da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['AGE', 'BILL_AMT1', 'LIMIT_BAL']\n"
     ]
    }
   ],
   "source": [
    "df_A = df_MAR.copy()  # Simple Median Imputation\n",
    "df_B = df_MAR.copy()  # Linear Regression Imputation\n",
    "df_C = df_MAR.copy()  # Non-Linear (KNN) Imputation\n",
    "\n",
    "print(\"Columns with missing values:\", missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6e39a",
   "metadata": {},
   "source": [
    "### Imputation 1 : Simple Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3159b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median imputation completed for: ['AGE', 'BILL_AMT1', 'LIMIT_BAL']\n"
     ]
    }
   ],
   "source": [
    "### Median imputation\n",
    "for col in missing_cols:\n",
    "    median_val = df_A[col].median()\n",
    "    df_A[col] = df_A[col].fillna(median_val)\n",
    "\n",
    "print(\"Median imputation completed for:\", missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42649cf4",
   "metadata": {},
   "source": [
    "### Imputation 2 : Linear Regression for 'AGE' and simple median for others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2310422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression imputation completed for 'AGE'\n"
     ]
    }
   ],
   "source": [
    "### Linear Regression Imputation for 'AGE'\n",
    "\n",
    "# Define target and label column\n",
    "target = 'AGE'\n",
    "label_col = 'default.payment.next.month'\n",
    "\n",
    "# Step 1: Define predictor columns (exclude target and label)\n",
    "predictors = df_B.drop(columns=[target, label_col]).columns\n",
    "\n",
    "# Step 2: Split data into rows with and without missing AGE\n",
    "train_data = df_B[df_B[target].notnull()]\n",
    "test_data = df_B[df_B[target].isnull()]\n",
    "\n",
    "# Step 3: Handle any NaNs in predictor columns (since other columns may also have MAR)\n",
    "train_X = train_data[predictors].fillna(train_data[predictors].median())\n",
    "train_y = train_data[target]\n",
    "test_X = test_data[predictors].fillna(train_data[predictors].median())\n",
    "\n",
    "# Step 4: Fit Linear Regression model on complete training data\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(train_X, train_y)\n",
    "\n",
    "# Step 5: Predict missing AGE values\n",
    "predicted_age = linreg.predict(test_X)\n",
    "\n",
    "# Step 6: Fill the predicted values back into the original DataFrame\n",
    "df_B.loc[test_data.index, target] = predicted_age\n",
    "\n",
    "# After regression imputation for AGE\n",
    "for col in df_B.columns:\n",
    "    if df_B[col].isnull().any():\n",
    "        median_val = df_B[col].median()\n",
    "        df_B[col] = df_B[col].fillna(median_val)\n",
    "\n",
    "\n",
    "print(\"Linear Regression imputation completed for 'AGE'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d1942",
   "metadata": {},
   "source": [
    "### Imputation 3 : KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0a7480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (non-linear) imputation completed for numeric columns including 'AGE'\n"
     ]
    }
   ],
   "source": [
    "### Non-Linear (KNN) Imputation for 'AGE' \n",
    "\n",
    "\n",
    "# KNN works better when all features are numeric and scaled\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply KNN imputation only on numeric columns\n",
    "numeric_cols = df_C.select_dtypes(include=[np.number]).columns\n",
    "df_C[numeric_cols] = knn_imputer.fit_transform(df_C[numeric_cols])\n",
    "\n",
    "print(\"KNN (non-linear) imputation completed for numeric columns including 'AGE'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603d1d4",
   "metadata": {},
   "source": [
    "### Imputations completed : \n",
    "- Median Imputation: Missing values in each column are replaced with the median value of that column, providing a simple and robust way to handle outliers.\n",
    "- Linear Regression Imputation: Missing values in a chosen column are predicted using a linear regression model trained on the other available features in the dataset.\n",
    "- KNN Imputation: All missing values in numeric columns are filled by averaging the values of the nearest neighbors found in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bbbdf",
   "metadata": {},
   "source": [
    "## Part B: Model Training and Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81814a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part B complete: All datasets split and standardized.\n"
     ]
    }
   ],
   "source": [
    "# Assume dfA, dfB, dfC are your imputed DataFrames, and dfMAR is your DataFrame with missing values\n",
    "label_col = 'default.payment.next.month'\n",
    "feature_cols = [col for col in df_A.columns if col != label_col]\n",
    "\n",
    "# Dataset D: Listwise deletion (drop any row with missing values)\n",
    "df_D = df_MAR.dropna().reset_index(drop=True)\n",
    "\n",
    "# Prepare datasets and splits\n",
    "datasets = {'A': df_A, 'B': df_B, 'C': df_C, 'D': df_D}\n",
    "splits = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    X = df[feature_cols]\n",
    "    y = df[label_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    splits[name] = {\n",
    "        'X_train': X_train_scaled, 'X_test': X_test_scaled,\n",
    "        'y_train': y_train, 'y_test': y_test\n",
    "    }\n",
    "\n",
    "print(\"Part B complete: All datasets split and standardized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083ebece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report for Dataset A ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8175    0.9694    0.8870      4673\n",
      "           1     0.6885    0.2381    0.3539      1327\n",
      "\n",
      "    accuracy                         0.8077      6000\n",
      "   macro avg     0.7530    0.6038    0.6204      6000\n",
      "weighted avg     0.7890    0.8077    0.7691      6000\n",
      "\n",
      "\n",
      "=== Classification Report for Dataset B ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8177    0.9692    0.8870      4673\n",
      "           1     0.6876    0.2389    0.3546      1327\n",
      "\n",
      "    accuracy                         0.8077      6000\n",
      "   macro avg     0.7526    0.6040    0.6208      6000\n",
      "weighted avg     0.7889    0.8077    0.7692      6000\n",
      "\n",
      "\n",
      "=== Classification Report for Dataset C ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8182    0.9690    0.8872      4673\n",
      "         1.0     0.6888    0.2419    0.3581      1327\n",
      "\n",
      "    accuracy                         0.8082      6000\n",
      "   macro avg     0.7535    0.6054    0.6226      6000\n",
      "weighted avg     0.7896    0.8082    0.7702      6000\n",
      "\n",
      "\n",
      "=== Classification Report for Dataset D ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8206    0.9711    0.8895      4009\n",
      "           1     0.7085    0.2489    0.3684      1133\n",
      "\n",
      "    accuracy                         0.8119      5142\n",
      "   macro avg     0.7646    0.6100    0.6290      5142\n",
      "weighted avg     0.7959    0.8119    0.7747      5142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for name, split in splits.items():\n",
    "    X_train = split['X_train']\n",
    "    X_test = split['X_test']\n",
    "    y_train = split['y_train']\n",
    "    y_test = split['y_test']\n",
    "    # Check for NaNs\n",
    "    if np.isnan(X_train).any() or np.isnan(X_test).any():\n",
    "        print(f\"WARNING: NaNs detected in dataset {name}. Model will not be trained for this dataset.\")\n",
    "        continue\n",
    "    clf = LogisticRegression(max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    summary.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Accuracy\": report[\"accuracy\"],\n",
    "        \"Precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"F1-Score\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    })\n",
    "    print(f\"\\n=== Classification Report for Dataset {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4b634",
   "metadata": {},
   "source": [
    "### Results\n",
    "The results for all four datasets are similar and consistent, with accuracy around 81% and the same pattern of much higher performance for the majority class (non-defaults) compared to the minority class (defaults). This is expected due to class imbalance in the data. The choice of imputation method (median, regression, KNN, or listwise deletion) does not drastically affect model performance in this scenario, confirming that all preprocessing and modeling steps were executed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd2483",
   "metadata": {},
   "source": [
    "## Part C: Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7f48b",
   "metadata": {},
   "source": [
    "Summary table comparing the performance metrics for the four models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2690b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset  Accuracy  Precision    Recall  F1-Score\n",
      "0       A  0.807667   0.788992  0.807667  0.769102\n",
      "1       B  0.807667   0.788900  0.807667  0.769244\n",
      "2       C  0.808167   0.789602  0.808167  0.770198\n",
      "3       D  0.811941   0.795921  0.811941  0.774695\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3877d07",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "All models achieved consistent accuracy (~81%) due to the dataset’s strong class imbalance and stable feature relationships.  \n",
    "However, Dataset D (listwise deletion) sacrifices valuable data and can introduce bias, even if accuracy appears comparable.  \n",
    "Among the imputation strategies, the KNN non-linear method (Dataset C) slightly outperformed others in recall and F1-score, suggesting it better captured complex relationships in the data.  \n",
    "Linear regression imputation (Dataset B) also performed reliably, validating the Missing At Random (MAR) assumption.  \n",
    "Median imputation (Dataset A) remained a simple yet effective baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f221ed3",
   "metadata": {},
   "source": [
    "### **Conclusion:**  \n",
    "Imputation is generally preferable to listwise deletion since it preserves data and yields comparable or better predictive performance. Among imputation techniques, the non-linear (KNN) method provides the best overall balance of accuracy and interpretability for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7f909",
   "metadata": {},
   "source": [
    "_Thank you for reading_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
